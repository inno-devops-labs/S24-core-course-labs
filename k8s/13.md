# Part 2
- Answering the question:
Explain why ordering guarantees are unnecessary for your app - all pods are the same and are responsible for the same task
- Implement a way to instruct the StatefulSet controller to launch or terminate all Pods in parallel - added podManagementPolicy: Parallel
to the values.yaml
```bash
(venv) smasiner@smasIners-MacBook-Pro k8s % kubectl get po,sts,svc,pvc
NAME            READY   STATUS    RESTARTS   AGE
pod/helmapp-0   1/1     Running   0          3m22s
pod/helmapp-1   1/1     Running   0          3m22s
pod/helmapp-2   1/1     Running   0          3m22s

NAME                       READY   AGE
statefulset.apps/helmapp   3/3     3m22s

NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
service/helmapp      ClusterIP   10.110.25.189   <none>        8080/TCP   3m22s
service/kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP    4h25m
(venv) smasiner@smasIners-MacBook-Pro k8s % 

```

# Part 1
- values are moved to the values.yaml
- result of the command:
```bash
(venv) smasiner@smasIners-MacBook-Pro k8s % helm install --dry-run --debug helmapp ./helmapp  
install.go:224: 2024-11-17 01:00:09.423512 +0300 MSK m=+0.062231103 [debug] Original chart version: ""
install.go:241: 2024-11-17 01:00:09.429059 +0300 MSK m=+0.067778066 [debug] CHART PATH: /Users/smasiner/Documents/GitHub/Iwanttodie/Untitled/S24-core-course-labs/k8s/helmapp

NAME: helmapp
LAST DEPLOYED: Sun Nov 17 01:00:09 2024
NAMESPACE: default
STATUS: pending-install
REVISION: 1
USER-SUPPLIED VALUES:
{}

COMPUTED VALUES:
affinity: {}
autoscaling:
  enabled: false
  maxReplicas: 100
  minReplicas: 1
  targetCPUUtilizationPercentage: 80
fullnameOverride: ""
image:
  pullPolicy: Always
  repository: smasiner2/python_app
  tag: latest
imagePullSecrets: []
ingress:
  annotations: {}
  className: ""
  enabled: false
  hosts:
  - host: chart-example.local
    paths:
    - path: /
      pathType: ImplementationSpecific
  tls: []
livenessProbe:
  httpGet:
    path: /
    port: http
mySecret: abraabra
nameOverride: ""
nodeSelector: {}
podAnnotations:
  vault.hashicorp.com/agent-inject: "true"
  vault.hashicorp.com/agent-inject-secret-database-config.txt: internal/data/database/config
  vault.hashicorp.com/agent-inject-status: update
  vault.hashicorp.com/agent-inject-template-database-config.txt: '{{- with secret
    "internal/data/database/config" -}}Bearer token: {{ .Data.data.token }}{{- end
    -}}'
  vault.hashicorp.com/role: internal-app
podLabels: {}
podManagementPolicy: Parallel
podSecurityContext: {}
readinessProbe:
  httpGet:
    path: /
    port: http
replicaCount: 3
resources: {}
securityContext: {}
service:
  port: 8080
  type: ClusterIP
serviceAccount:
  annotations: {}
  automount: true
  create: true
  name: ""
tolerations: []
volumeMounts:
- mountPath: /config.json
  name: config
  readOnly: true
  subPath: config.json
volumes:
- configMap:
    name: config-configmap
  name: config

HOOKS:
---
# Source: helmapp/templates/post-install-hook.yaml
apiVersion: v1
kind: Pod
metadata:
   name: postinstall-hook
   annotations:
       "helm.sh/hook": "post-install"
       "helm.sh/hook-delete-policy": hook-succeeded,hook-failed
spec:
  containers:
  - name: post-install-container
    image: busybox
    imagePullPolicy: Always
    command: ['sh', '-c', 'echo The post-install hook is running && sleep 15' ]
  restartPolicy: Never
  terminationGracePeriodSeconds: 0
---
# Source: helmapp/templates/pre-install-hook.yaml
apiVersion: v1
kind: Pod
metadata:
   name: preinstall-hook
   annotations:
       "helm.sh/hook": "pre-install"
       "helm.sh/hook-delete-policy": hook-succeeded,hook-failed
spec:
  containers:
  - name: pre-install-container
    image: busybox
    imagePullPolicy: IfNotPresent
    command: ['sh', '-c', 'echo The pre-install hook is running && sleep 20' ]
  restartPolicy: Never
  terminationGracePeriodSeconds: 0
---
# Source: helmapp/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "helmapp-test-connection"
  labels:
    helm.sh/chart: helmapp-0.1.0
    app.kubernetes.io/name: helmapp
    app.kubernetes.io/instance: helmapp
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args: ['helmapp:8080']
  restartPolicy: Never
MANIFEST:
---
# Source: helmapp/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: helmapp
  labels:
    helm.sh/chart: helmapp-0.1.0
    app.kubernetes.io/name: helmapp
    app.kubernetes.io/instance: helmapp
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: true
---
# Source: helmapp/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-secret
type: Opaque
data:
  MY_PASS: "YWJyYWFicmE="
---
# Source: helmapp/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: config-configmap
data:
  config.json: |-
    {"abra" : "kadabra"}
---
# Source: helmapp/templates/envconfig.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: env-configmap
data:
  MY_SECRET: "a"
---
# Source: helmapp/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: helmapp
  labels:
    helm.sh/chart: helmapp-0.1.0
    app.kubernetes.io/name: helmapp
    app.kubernetes.io/instance: helmapp
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: helmapp
    app.kubernetes.io/instance: helmapp
---
# Source: helmapp/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: helmapp
  labels:
    helm.sh/chart: helmapp-0.1.0
    app.kubernetes.io/name: helmapp
    app.kubernetes.io/instance: helmapp
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 3
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app.kubernetes.io/name: helmapp
      app.kubernetes.io/instance: helmapp
  template:
    metadata:
      annotations:
        vault.hashicorp.com/agent-inject: "true"
        vault.hashicorp.com/agent-inject-secret-database-config.txt: internal/data/database/config
        vault.hashicorp.com/agent-inject-status: update
        vault.hashicorp.com/agent-inject-template-database-config.txt: '{{- with secret "internal/data/database/config"
          -}}Bearer token: {{ .Data.data.token }}{{- end -}}'
        vault.hashicorp.com/role: internal-app
      labels:
        helm.sh/chart: helmapp-0.1.0
        app.kubernetes.io/name: helmapp
        app.kubernetes.io/instance: helmapp
        app.kubernetes.io/version: "1.16.0"
        app.kubernetes.io/managed-by: Helm
    spec:
      serviceAccountName: helmapp
      securityContext:
        {}
      containers:
        - name: helmapp
          securityContext:
            {}
          image: "smasiner2/python_app:latest"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 8080 # gets it from values
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /
              port: http
          readinessProbe:
            httpGet:
              path: /
              port: http
          resources:
            {}
          volumeMounts:
            - mountPath: /config.json
              name: config
              readOnly: true
              subPath: config.json
          envFrom:
            - configMapRef:
                name: env-configmap
          env:
            - name: MY_PASS
              valueFrom:
                secretKeyRef:
                  name: my-secret
                  key: MY_PASS
      volumes:
        - configMap:
            name: config-configmap
          name: config

NOTES:
1. Get the application URL by running these commands:
  export POD_NAME=$(kubectl get pods --namespace default -l "app.kubernetes.io/name=helmapp,app.kubernetes.io/instance=helmapp" -o jsonpath="{.items[0].metadata.name}")
  export CONTAINER_PORT=$(kubectl get pod --namespace default $POD_NAME -o jsonpath="{.spec.containers[0].ports[0].containerPort}")
  echo "Visit http://127.0.0.1:8080 to use your application"
  kubectl --namespace default port-forward $POD_NAME 8080:$CONTAINER_PORT
(venv) smasiner@smasIners-MacBook-Pro k8s % 

```